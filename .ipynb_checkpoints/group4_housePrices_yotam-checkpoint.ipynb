{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Data Analytics and Prediction\n",
    "\n",
    "## Group #4 - Housing Prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for development stages\n",
    "DEBUG_MODE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eilon - used for development stage - I need to set my working directory manually\n",
    "EILON_SET_WORK_DIR = False\n",
    "if (EILON_SET_WORK_DIR):\n",
    "# Now change the directory\n",
    "    import os\n",
    "    os.chdir(\"C:/Users/bareilon/Documents/Personal/MBA/IDC BIG DATA/Mini Semester 1/Business Data Analytics/exercises/IDC-BDA-Exercises\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Business objectives and targets\n",
    "\n",
    "#### Business objective: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read, explore and prepare data\n",
    "\n",
    "#### 2.1. Download and read the data\n",
    "\n",
    "The dataset is taken from a Kaggle competition: <br>\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n",
    "\n",
    "Read the csv file to a data frame. Note that the data is already split to train and test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Taking a quick look at the data \n",
    "Using the functions: \n",
    "* head\n",
    "* info \n",
    "* describe\n",
    "\n",
    "\n",
    "1. The prediction target (y) is the SalePrice column.\n",
    "2. Data manipulation - we are going to drop all the categorical columns, as we don'tknow how to handle them yet.\n",
    "3. We will handle some missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"Data/train.csv\")\n",
    "train_len = df_train.shape[0]\n",
    "df_test = pd.read_csv(\"Data/test.csv\")\n",
    "df_test[\"SalePrice\"] = 0 \n",
    "#df_train = df_train.drop(\"SalePrice\", axis = 1)\n",
    "df_merged = df_train.append(df_test)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graph_with_labels(adjacency_matrix):\n",
    "    rows, cols = np.where(adjacency_matrix == 1)\n",
    "    edges = zip(rows.tolist(), cols.tolist())\n",
    "    gr = nx.Graph()\n",
    "    gr.add_edges_from(edges)\n",
    "    nx.draw(gr, node_size=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "corrTH = 0.4\n",
    "corr_mat = df_merged[df_merged.select_dtypes(exclude='object').columns].corr()\n",
    "#corr_mat = df_merged_numeric.corr()\n",
    "corr_matTH = (corr_mat > corrTH) | (corr_mat < -corrTH)\n",
    "#sns.heatmap(corr_matTH)\n",
    "#display(corr_matTH)\n",
    "#show_graph_with_labels(corr_matTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_list():\n",
    "    _null_list = df_merged.isna().sum()\n",
    "    _null_list = _null_list[_null_list > 0].sort_values(ascending=False)\n",
    "    return _null_list\n",
    "\n",
    "null_list = get_null_list()\n",
    "null_list.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable: PoolQC\n",
    "#### if the Pool Area is 0, the the Pool QC is 'NA', as described in the Data Description file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (df_merged.PoolArea == 0) & (df_merged.PoolQC.isna() == True)\n",
    "df_merged.loc[idx, 'PoolQC'] = df_merged.loc[idx, 'PoolQC'].fillna('NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But we still have 3 outliers... Houses with pools but the qaulity is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[(df_merged.PoolQC.isna() == True) & (df_merged.PoolArea > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.PoolQC.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data of the houses withe pools but no quality grading.\n",
    "We'll review these features: Overall Condition, External Condition, Garage Condition, Heating Quality etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_cols = ['OverallCond','ExterCond','ExterQual','GarageCond','GarageQual','HeatingQC','FireplaceQu','KitchenQual','BsmtFinType1','BsmtFinType2','Fence','PoolQC']\n",
    "df_merged[qc_cols][(df_merged.PoolQC.isna() == True) & (df_merged.PoolArea > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there was a lot of data, we could build a model to predict this variable based on other qulity fators. \n",
    "Since there aren't enough houses with pools, we can assume the quality is Typical/Average (TA), basd on the other parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (df_merged.PoolQC.isna() == True) & (df_merged.PoolArea > 0)\n",
    "df_merged.loc[idx, 'PoolQC'] = df_merged.loc[idx, 'PoolQC'].fillna('TA')\n",
    "df_merged.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.PoolQC.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.PoolQC.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'MiscFeature' Column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's overview the 'MiscFeature' column\n",
    "According to the data description:\n",
    "MiscFeature: Miscellaneous feature not covered in other categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.MiscFeature.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fill in all the null values with 'NA'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_merged.MiscFeature.isna()\n",
    "df_merged.loc[idx, 'MiscFeature'] = df_merged.loc[idx, 'MiscFeature'].fillna('NA')\n",
    "df_merged[idx].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait, let's check of there is a house with a Miscellaneous Value greater then 0 that we wrongly labeled 'MiscFeature' as 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (df_merged.MiscFeature == 'NA') & (df_merged.MiscVal > 0)\n",
    "df_merged[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There i one house that we missslabeled. Without other info, we will set it to \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.loc[idx, 'MiscFeature'] = 'Othr'\n",
    "df_merged[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.MiscFeature.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.MiscFeature.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fence Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.Fence.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_merged.Fence.isna()\n",
    "df_merged.loc[idx, 'Fence'] = df_merged.loc[idx, 'Fence'].fillna('NA')\n",
    "df_merged[idx].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.Fence.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alley Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.Alley.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_merged.Alley.isna()\n",
    "df_merged.loc[idx, 'Alley'] = df_merged.loc[idx, 'Alley'].fillna('NA')\n",
    "df_merged[idx].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.Alley.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'FireplaceQu' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.FireplaceQu.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'FireplaceQu'\n",
    "idx = df_merged[col].isna()\n",
    "df_merged.loc[idx, col] = df_merged.loc[idx, col].fillna('NA')\n",
    "df_merged[idx].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.FireplaceQu.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we miss labeled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[(df_merged.Fireplaces > 0) & (df_merged.FireplaceQu == 'NA')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we're good..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garage relaed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns related to Garages \n",
    "cols = df_merged.filter(regex='Garage').columns\n",
    "cols = cols.values\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find indexes of homes without garages\n",
    "idx = df_merged[(df_merged.GarageType.isna()) & (df_merged.GarageYrBlt.isna()) & (df_merged.GarageFinish.isna()) & \\\n",
    "                (df_merged.GarageCars == 0)   & (df_merged.GarageArea == 0)    & (df_merged.GarageQual.isna())   & \\\n",
    "                (df_merged.GarageCond.isna()) ].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values\n",
    "df_merged.loc[idx, 'GarageType'] = df_merged.loc[idx, 'GarageType'].fillna('NA')\n",
    "df_merged.loc[idx, 'GarageFinish'] = df_merged.loc[idx, 'GarageFinish'].fillna('NA')\n",
    "df_merged.loc[idx, 'GarageQual'] = df_merged.loc[idx, 'GarageQual'].fillna('NA')\n",
    "df_merged.loc[idx, 'GarageCond'] = df_merged.loc[idx, 'GarageCond'].fillna('NA')\n",
    "df_merged.loc[idx, 'GarageYrBlt'] = df_merged.loc[idx, 'GarageYrBlt'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_list = df_merged[cols].isna().sum()\n",
    "null_list[null_list > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have a few rows with missing values ralted to Garages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ((df_merged.GarageCond.isna()) | (df_merged.GarageYrBlt.isna()) | (df_merged.GarageFinish.isna()) | \\\n",
    "                (df_merged.GarageQual.isna()) | (df_merged.GarageCond.isna()) | (df_merged.GarageYrBlt.isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.loc[idx, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the year the house was built\n",
    "df_merged.loc[idx, 'GarageYrBlt'] = df_merged.loc[idx, 'YearBuilt']\n",
    "df_merged.loc[idx,cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill in the 'Finish' based on the most common value for 'Detached' Garages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.GarageFinish[df_merged.GarageType == 'Detchd'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most 'Detached' Garages are 'Unf' (Unfinished), we will set the value to 'Unf'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.loc[idx, 'GarageFinish'] = 'Unf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.GarageArea[df_merged.GarageType == 'Detchd'].count()\n",
    "df_merged.loc[idx,cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the same for Garage Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.GarageQual[df_merged.GarageType == 'Detchd'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the most common quality for Detached Garages which is 'TA'\n",
    "df_merged.loc[idx, 'GarageQual'] = 'TA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again for Garage Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the most common Condition for Detached Garages which is 'TA'\n",
    "df_merged.loc[idx, 'GarageCond'] = 'TA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.GarageCond[df_merged.GarageType == 'Detchd'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to handle row id 1116.\n",
    "Let's try to estimate the size of the Garage, based on the year the house was built.\n",
    "We assume garages back then had some stadard size, and most families owned one car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_min = 1920\n",
    "_max = 1925\n",
    "df_merged[(df_merged.GarageYrBlt > _min) & (df_merged.GarageYrBlt < _max)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['GarageCars'][(df_merged.GarageYrBlt > _min) & (df_merged.GarageYrBlt < _max)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1116\n",
    "garage_mean_area = df_merged['GarageArea'][(df_merged.GarageYrBlt > _min) & (df_merged.GarageYrBlt < _max) & (df_merged.GarageCars == 1)].mean()\n",
    "df_merged.loc[idx, 'GarageCars'] = 1.0\n",
    "df_merged.loc[idx, 'GarageArea'] = round(garage_mean_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LotFrontage\n",
    "It seems this column is tricky. \n",
    "We can build a model to estimate the value \n",
    "as described in https://www.kaggle.com/sangxia/filling-in-the-missing-lotfrontage-values/notebook <br>\n",
    "Let's examine the correlation between the 'SalePrice' and the 'LotFrontage' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df_merged[:train_len].copy()\n",
    "df_corr['SalePrice'] = df.SalePrice.astype(int)\n",
    "df_corr = df_corr[df_corr.LotFrontage > 0] \n",
    "df_corr = df_corr.loc[: ,['LotFrontage','SalePrice']]\n",
    "df_corr.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a 35% correlation which is not too high, nor too low.\n",
    "For now, we will fill in the Mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_merged.LotFrontage.notnull()\n",
    "area_to_frontage = df_merged.loc[idx, 'LotArea'] / df_merged.loc[idx, 'LotFrontage'] \n",
    "area_to_frontage.mean()\n",
    "sns.distplot(area_to_frontage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "Try to set LotFrontage nulls based on neighborhoood\n",
    "\n",
    "LotFrontage : Since the area of each street connected to the house property most likely have a similar area to other houses in its neighborhood , we can fill in missing values by the median LotFrontage of the neighborhood.\n",
    "#Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\n",
    "all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_merged.LotFrontage.isna()\n",
    "df_merged.loc[idx, 'LotFrontage'] =  df_merged.LotFrontage.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basement Realted Columns\n",
    "BsmtExposure    82 <br>\n",
    "BsmtCond        82 <br>\n",
    "BsmtQual        81 <br>\n",
    "BsmtFinType2    80 <br>\n",
    "BsmtFinType1    79 <br>\n",
    "\n",
    "and we also have other related columns: <br>\n",
    "TotalBsmtSF <br>\n",
    "BsmtUnfSF <br>\n",
    "BsmtFullBath <br>\n",
    "BsmtHalfBath <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_merged.filter(regex='Bsmt').columns\n",
    "cols = cols.values\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in 0 if the TotalBsmtSF is null\n",
    "idx = df_merged.TotalBsmtSF.isna()\n",
    "df_merged.loc[idx, 'TotalBsmtSF'] = df_merged.loc[idx, 'TotalBsmtSF'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indexes of rows with missing Basement parameters\n",
    "idx = ((df_merged.BsmtQual.isna()) & (df_merged.BsmtCond.isna()) & (df_merged.BsmtExposure.isna()) & \\\n",
    "                (df_merged.BsmtFinType1.isna()) & (df_merged.BsmtFinType2.isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.loc[idx, cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (df_merged.TotalBsmtSF == 0.0)\n",
    "str_cols = ['BsmtExposure','BsmtCond','BsmtQual','BsmtFinType1','BsmtFinType2']\n",
    "df_merged.loc[idx, str_cols] = df_merged.loc[idx, str_cols].apply(lambda x: x.fillna('NA'), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ((df_merged.TotalBsmtSF == 0) & ((df_merged.BsmtUnfSF.isna()) | (df_merged.BsmtFullBath.isna()) | \\\n",
    "                (df_merged.BsmtHalfBath.isna())))\n",
    "num_cols = ['BsmtFinSF1','BsmtFinSF2','BsmtHalfBath','BsmtFullBath', 'BsmtUnfSF']\n",
    "df_merged.loc[idx, num_cols] = df_merged.loc[idx, num_cols].apply(lambda x: x.fillna(0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged[cols][df_merged.TotalBsmtSF == 0]\n",
    "df_merged.loc[:,cols][df_merged.loc[:,cols].isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.BsmtQual.value_counts()\n",
    "df_merged[df_merged.BsmtQual.isna()] = df_merged[df_merged.BsmtQual.isna()].fillna('TA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.BsmtCond.value_counts()\n",
    "df_merged[df_merged.BsmtCond.isna()] = df_merged[df_merged.BsmtCond.isna()].fillna('TA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.BsmtExposure.value_counts()\n",
    "df_merged[df_merged.BsmtExposure.isna()] = df_merged[df_merged.BsmtExposure.isna()].fillna('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.BsmtFinType2.value_counts()\n",
    "df_merged[df_merged.BsmtFinType2.isna()] = df_merged[df_merged.BsmtFinType2.isna()].fillna('Unf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas_cols = ['MasVnrType', 'MasVnrArea']\n",
    "df_merged[mas_cols][df_merged[mas_cols].isnull().any(axis=1)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.MasVnrType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ( (df_merged.MasVnrType.isna()) & (df_merged.MasVnrArea > 0.0) )\n",
    "df_merged.loc[idx, 'MasVnrType'] = df_merged.loc[idx, 'MasVnrType'].fillna('BrkFace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ( (df_merged.MasVnrType.isna()) & (df_merged.MasVnrArea.isna()) )\n",
    "df_merged.loc[idx, 'MasVnrType'] = df_merged.loc[idx, 'MasVnrType'].fillna('None')\n",
    "df_merged.loc[idx, 'MasVnrArea'] = df_merged.loc[idx, 'MasVnrArea'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check what is still missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "null_list = get_null_list()\n",
    "null_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSZoning Column <br>\n",
    "4 missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.MSZoning.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'RL' is the most common value so we can assume the missing values are RL.\n",
    "We can also try later to reun the model with nulls and see the differance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_merged.MSZoning.isna()\n",
    "df_merged.loc[idx, 'MSZoning'] = df_merged.loc[idx, 'MSZoning'].fillna('RL')\n",
    "df_merged.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.Functional.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typ (Typical) is the most common value.\n",
    "The data description file tells us we can assume Typical unless specified differently:\n",
    "Functional: Home functionality (Assume typical unless deductions are warranted)\n",
    "Hence, we will fill in Typ for the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged.Functional.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'Functional'\n",
    "df_merged[col] = df_merged[col].fillna('Typ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_list = get_null_list()\n",
    "null_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'Utilities'\n",
    "df_merged[df_merged[col].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[col].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'AllPub' is the most common value (99.99 percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[col] = df_merged[col].fillna('AllPub')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill 'None' SaleType, KitchenQual, Electrical, Exterior2nd, Exterior1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cols = ['SaleType', 'KitchenQual', 'Electrical', 'Exterior2nd', 'Exterior1st']\n",
    "for col in null_cols:\n",
    "    df_merged[col] = df_merged[col].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No more missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_list = get_null_list()\n",
    "null_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Nominal variables into dummies\n",
    "df_merged = pd.get_dummies(df_merged) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Exploratory data analytics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data exploration is required to understand what is your data, and which preparations are required on it. A common visualization is a histogram. Use histogram to understand the values distribution, because many statistical model assume normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not DEBUG_MODE):\n",
    "    df_merged.hist(bins = 25, figsize = (20,15)) #Check the hist parameters by clicking on the Tab completion. \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not DEBUG_MODE):\n",
    "    df_merged.LotArea[df_merged['LotArea'] < 5000].hist(bins = 50, figsize = (10,5)) #Check the hist parameters by clicking on the Tab completion. \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not DEBUG_MODE):\n",
    "    display(df_merged.isnull().sum(),df_merged.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Data manipulations\n",
    "\n",
    "After we looked at the data we can prepare it to analysis. \n",
    "\n",
    "From understanding the histograms, and talking with experts we might decide to drop or change columns, or to split the data by rows. \n",
    "\n",
    "For example: \n",
    "\n",
    "...\n",
    "\n",
    "An option that we will take here to handle this is:\n",
    "1. Take out the few rows and put them aside for separate handling\n",
    "2. Drop this predictor from data\n",
    "\n",
    "(Note that after the data manipulation you can rerun the describe or histogram above to see changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically data scientists continue back and forth between diffrent data visualizations and manipulations, but for this exercise we will stop here. We will dive more to this on next lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5. Categorical values\n",
    "\n",
    "Data manipulations require also handling of categorical data, and transforming it to be numerical. In our example, 'work_accident' and 'sales' are categorical that already appear as numerical. However, 'sales' and 'salary' are categorical with non-numeric data. We will learn how to handle such variables on next lesson, for now, lets just remove these columns.\n",
    "\n",
    "You can learn more on the drop function in pandas, in: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6. Transform the data to matrix of X and y, spliting to Train and Test\n",
    "\n",
    "Let's now prepae to modeling:\n",
    "1. Split between X the predictors and y the target\n",
    "2. Turn from data frame to matrix\n",
    "3. Split X and y to train data set and test data set, with matching indexes between X and y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train_test_split is the first function we are using from sklearn.\n",
    "Learn more about it function at: <br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html \n",
    "\n",
    "\n",
    "sklearn handles numpy arrays, whereas until now we handled a dataframe.\n",
    "Lets check that indeed we changed the type:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Variable\n",
    "\n",
    "SalePrice is the variable we decided to predict. So let's analyze this variable.\n",
    "We plotted a graph of salePrice. Since target distribution is not normalized, we performed log-transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df_merged[:train_len].copy()\n",
    "df_corr['SalePrice'] = df.SalePrice.astype(int)\n",
    "sns.distplot(df_corr['SalePrice'], fit=norm)\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(df_corr['SalePrice'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "#Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_corr['SalePrice'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "df_corr['SalePriceLog'] = np.log1p(df_corr['SalePrice'])\n",
    "#Check the new distribution \n",
    "sns.distplot(df_corr['SalePriceLog'] , fit=norm);\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(df_corr['SalePriceLog'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "#Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_corr['SalePriceLog'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged[:train_len].copy()\n",
    "#split the data into train and test sections\n",
    "train_df, test_df= train_test_split (df, test_size = 0.2, random_state=7) \n",
    "# train_test_split is from sklearn. It requiers that the data will be a numpy array, that is numbers only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Train Data\n",
    "X_train = train_df.drop('SalePrice',axis=1).values\n",
    "y_train = train_df['SalePrice'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Test Data\n",
    "X_test = test_df.drop('SalePrice',axis=1).values\n",
    "y_test = test_df['SalePrice'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit a model, learning\n",
    "\n",
    "To fit a model means to train the selected model(s) on X_train and y_train.\n",
    "Most of this course will be dedicated to modeling fit and evaluation.\n",
    "Yet, the model fiting itself is very short in programming, because the models are already programed in sklearn.\n",
    "The programming for fiting a model (learning) includes 2 commands:\n",
    "1. Select a model\n",
    "2. Fit command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Select a model\n",
    "\n",
    "In this example we will use a model of type tree, that is called decision tree.\n",
    "We will first import it from sklearn. Note that there is a decision trees for regresssion and a diffrent one for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Fit the selected model\n",
    "Training the model, using sklearn, is typically only one command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model evaluation\n",
    "\n",
    "Evaluating the model can also be done in one command.\n",
    "\n",
    "We can evalute the model that was trained on train_x by its prediction of test_x compared to test_y in one command. On next lessons we will learn more evaluation methods, as usually decision is taken by combined evaluation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = reg.score(X=X_train, y=y_train) \n",
    "train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the evaluation on test was very good. Yet, model score on train is much higher. This may indicate that we might be in an overfit to the train data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = reg.score(X=X_test, y=y_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_score - test_score) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Model\n",
    "### Gradient Boosting Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "clf = ensemble.GradientBoostingRegressor(n_estimators = 500, max_depth = 10, min_samples_split = 2,\n",
    "          learning_rate = 0.1, loss = 'ls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = clf.score(X_train ,y_train)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = clf.score(X_test ,y_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now do it in loop in order to find the best fitting for ietch model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_test_split(df, rs):\n",
    "    train_df, test_df= train_test_split (df, test_size = 0.2, random_state=rs)     \n",
    "    X_train = train_df.drop('SalePrice',axis=1).values\n",
    "    y_train = train_df['SalePrice'].values\n",
    "    X_test = test_df.drop('SalePrice',axis=1).values\n",
    "    y_test = test_df['SalePrice'].values\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def dif_err_estimate(train_score, test_score):\n",
    "    return (train_score - test_score) * 100\n",
    "\n",
    "def test_err_estimate(train_score, test_score):\n",
    "    return (1 - test_score) * 100\n",
    "\n",
    "    \n",
    "def Run_model(model_name, df, iteration_num, err_method):\n",
    "    rs = 7\n",
    "    errors = np.zeros(iteration_num)\n",
    "    min_errors = np.zeros(iteration_num)\n",
    "    min_err = 10000\n",
    "    if model_name == 'linear':\n",
    "        model = LinearRegression()\n",
    "    elif model_name == 'gbr':\n",
    "        model = ensemble.GradientBoostingRegressor(n_estimators = 500, max_depth = 10, min_samples_split = 2,\n",
    "          learning_rate = 0.1, loss = 'ls')\n",
    "    \n",
    "    for itr in range(iteration_num):\n",
    "        X_train, y_train, X_test, y_test = my_train_test_split(df,rs+itr)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        train_score = model.score(X=X_train, y=y_train) \n",
    "        test_score = model.score(X=X_test, y=y_test)\n",
    "        errors[itr] = (train_score - test_score) * 100#err_method(train_score, test_score)\n",
    "        if min_err > errors[itr]:\n",
    "            min_err = errors[itr]\n",
    "            best_model = model\n",
    "        min_errors[itr] = min_err\n",
    "                \n",
    "    return best_model, min_errors, errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Model\n",
    "linear_model, min_linear_errs, linear_errs= Run_model('linear', df, iteration_num, dif_err_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('last err: ', min_linear_errs[len(min_linear_errs)-1], '   first err = ', linear_errs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBR Model\n",
    "gbr_itr_n = 10\n",
    "gbr_model, min_gbr_errs, gbr_errs= Run_model('gbr', df, gbr_itr_n, dif_err_estimate)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1, iteration_num+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x[0:gbr_itr_n], gbr_errs, '--', x[0:gbr_itr_n], min_gbr_errs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('last err: ', min_gbr_errs[len(min_gbr_errs)-1], '   first err = ', gbr_errs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predict / Deploy model\n",
    "Now that we have a model that we are satisfied it we can run it on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 1, 1)\n",
    "#plt.scatter(X_test , y_test,label = 'Test')\n",
    "plt.scatter(y_test , y_pred,label = 'Predict')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction matched the actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on test data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged[train_len:].copy()\n",
    "X_pred = df.drop('SalePrice',axis=1).values\n",
    "kaggle_df = pd.DataFrame()\n",
    "kaggle_df['Id'] = df_merged.Id[train_len:]\n",
    "kaggle_df['SalePrice'] = clf.predict(X_pred)\n",
    "kaggle_df.to_csv('Prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Communicate\n",
    "Now that you have a good working model you need to communicate your results.\n",
    "\n",
    "If this is a predict project, you may decide not to communicate details externaly, only your evaluation results.\n",
    "\n",
    "You need to communicate how you got to the results, to customers on infer project, and internaly on predict project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
